{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Height Prediction Model Training - Run 7\n\n**Objective:** Fix Run 6 data leakage and improve model generalization\n\n## Run 7 Strategy - Critical Fixes:\n\n1. \u2705 **Move augmentation AFTER train-val split** (FIX DATA LEAKAGE!)\n2. \u2705 **Reduce augmentation** to 3/2/1 copies for hard/medium/easy\n3. \u2705 **Increase noise scale** to 5% (better generalization)\n4. \u2705 **Add early stopping** on easy case performance\n5. \u2705 **Implement balanced loss function**\n6. \u2705 **Create separate tier metrics tracking**\n7. \u2705 **Add L2 regularization**\n\n## Expected Performance:\n\n- Easy cases: < 0.15 log2-MSE (NO degradation from Run 2!)\n- Medium cases: 0.20-0.30 log2-MSE\n- Hard cases: 0.70-1.20 log2-MSE\n- Overall: 0.28-0.35 (beat 0.374 target with VALID metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport pickle\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import (\n    Input, Dense, Embedding, Flatten, Concatenate,\n    Dropout, Add, LayerNormalization, Lambda\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import (\n    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,\n    Callback, LearningRateScheduler\n)\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras import regularizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(\"=\"*70)\nprint(\"HEIGHT PREDICTION MODEL - RUN 7 (DATA LEAKAGE FIXED)\")\nprint(\"=\"*70)\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"STEP 1: Loading Data\")\nprint(\"-\"*70)\n\nwith open('data/combined_final_n_k_m_P.pkl', 'rb') as f:\n    inputs_raw = pickle.load(f)\n\nwith open('data/combined_final_mHeights.pkl', 'rb') as f:\n    outputs_raw = pickle.load(f)\n\nprint(f\"Raw input samples: {len(inputs_raw)}\")\nprint(f\"Raw output samples: {len(outputs_raw)}\")\nif len(inputs_raw) > 0:\n    sample = inputs_raw[0]\n    print(f\"Sample structure: [n={sample[0]}, k={sample[1]}, m={sample[2]}, P_matrix shape={sample[3].shape}]\")\nprint(f\"Output range: [{np.min(outputs_raw):.2f}, {np.max(outputs_raw):.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train-Val Split (BEFORE Augmentation!)\n\n**CRITICAL FIX from Run 6:** Split the data FIRST, then augment only the training set.\n\nThis prevents data leakage where augmented copies of validation samples end up in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"STEP 2: Train-Val Split (BEFORE Augmentation - Critical Fix!)\")\nprint(\"-\"*70)\n\n# Create stratification labels\nstratify_labels = np.array([k * 10 + m for n, k, m, P in inputs_raw])\n\n# Split on ORIGINAL data only\n(inputs_train_orig, inputs_val,\n outputs_train_orig, outputs_val) = train_test_split(\n    inputs_raw,\n    outputs_raw,\n    test_size=0.15,\n    random_state=42,\n    stratify=stratify_labels\n)\n\nprint(f\"Training samples (original): {len(inputs_train_orig)}\")\nprint(f\"Validation samples (original, NO augmentation): {len(inputs_val)}\")\nprint()\nprint(\"\u2705 CRITICAL FIX: Validation set contains ONLY original samples\")\nprint(\"\u2705 No data leakage - augmented copies stay in training set only\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Augmentation (Training Set ONLY!)\n\nApply augmentation with improved strategy:\n- Hard cases (k=5,m=4 | k=6,m=3 | k=4,m=5): +3 copies (was 50!)\n- Medium cases (k=4,m=4 | k=5,m=3 | k=6,m=2): +2 copies (was 25!)\n- Easy cases (k=4,m=2 | k=4,m=3 | k=5,m=2): +1 copy (was 0!)\n- Noise scale: 5% (was 2%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_sample(n, k, m, P_matrix, m_height, noise_scale=0.05):\n    \"\"\"\n    Augment a single sample with 5% noise (increased from 2%)\n    \"\"\"\n    # Add noise to n (\u00b15%)\n    n_aug = n * (1 + np.random.uniform(-noise_scale, noise_scale))\n    n_aug = max(1.0, n_aug)\n\n    # Add noise to P matrix\n    P_aug = P_matrix.copy()\n    if P_aug.size > 0:\n        noise = np.random.normal(0, noise_scale, P_aug.shape)\n        P_aug = P_aug + noise\n        P_aug = np.clip(P_aug, 0, 1)\n\n        # Renormalize rows to sum to 1\n        if len(P_aug.shape) == 2:\n            row_sums = P_aug.sum(axis=1, keepdims=True)\n            row_sums = np.maximum(row_sums, 1e-7)\n            P_aug = P_aug / row_sums\n\n    return (n_aug, k, m, P_aug), m_height\n\n\n# Define complexity groups\nEASY_GROUPS = [(4, 2), (4, 3), (5, 2)]\nMEDIUM_GROUPS = [(4, 4), (5, 3), (6, 2)]\nHARD_GROUPS = [(5, 4), (6, 3), (4, 5)]\n\n# Augmentation config - REDUCED from Run 6\naugmentation_config = {\n    (5, 4): 3, (6, 3): 3, (4, 5): 3,  # Hard: +3 (was 50!)\n    (4, 4): 2, (5, 3): 2, (6, 2): 2,  # Medium: +2 (was 25!)\n    (4, 2): 1, (4, 3): 1, (5, 2): 1,  # Easy: +1 (was 0!)\n}\n\n# Augment ONLY training data\ninputs_train_aug = []\noutputs_train_aug = []\n\nprint(\"Augmenting training data...\")\nfor sample, target in zip(inputs_train_orig, outputs_train_orig):\n    n, k, m, P_matrix = sample\n\n    # Always keep original\n    inputs_train_aug.append(sample)\n    outputs_train_aug.append(target)\n\n    # Add augmented copies\n    num_copies = augmentation_config.get((k, m), 0)\n    for _ in range(num_copies):\n        aug_sample, aug_target = augment_sample(n, k, m, P_matrix, target, noise_scale=0.05)\n        inputs_train_aug.append(aug_sample)\n        outputs_train_aug.append(aug_target)\n\nprint(f\"Training samples (original): {len(inputs_train_orig)}\")\nprint(f\"Training samples (augmented): {len(inputs_train_aug)}\")\nprint(f\"Augmentation ratio: {len(inputs_train_aug) / len(inputs_train_orig):.2f}x\")\nprint(f\"Validation samples: {len(inputs_val)} (NO augmentation)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"STEP 4: Preparing Data for Training\")\nprint(\"-\"*70)\n\ndef prepare_data(inputs_list, outputs_list):\n    \"\"\"Convert list of samples to arrays\"\"\"\n    n_values = []\n    k_values = []\n    m_values = []\n    P_matrices_flattened = []\n\n    for sample in inputs_list:\n        n_values.append(sample[0])\n        k_values.append(sample[1])\n        m_values.append(sample[2])\n        P_matrices_flattened.append(sample[3].flatten())\n\n    n_values = np.array(n_values, dtype=np.float32).reshape(-1, 1)\n    k_values = np.array(k_values, dtype=np.int32).reshape(-1, 1)\n    m_values = np.array(m_values, dtype=np.int32).reshape(-1, 1)\n    outputs_array = np.array(outputs_list, dtype=np.float32)\n\n    # Pad P matrices\n    max_p_size = max(len(p) for p in P_matrices_flattened)\n    P_matrices_padded = []\n\n    for p in P_matrices_flattened:\n        if len(p) < max_p_size:\n            padded = np.zeros(max_p_size, dtype=np.float32)\n            padded[:len(p)] = p\n            P_matrices_padded.append(padded)\n        else:\n            P_matrices_padded.append(p)\n\n    P_matrices = np.array(P_matrices_padded, dtype=np.float32)\n\n    return n_values, k_values, m_values, P_matrices, outputs_array\n\n# Prepare training data (augmented)\nn_train, k_train, m_train, P_train_raw, y_train = prepare_data(inputs_train_aug, outputs_train_aug)\n\n# Prepare validation data (original only)\nn_val, k_val, m_val, P_val_raw, y_val = prepare_data(inputs_val, outputs_val)\n\n# Normalize P matrices using ONLY training statistics\nscaler = StandardScaler()\nP_train = scaler.fit_transform(P_train_raw)\nP_val = scaler.transform(P_val_raw)\n\n# Ensure outputs >= 1.0\ny_train = np.maximum(y_train, 1.0)\ny_val = np.maximum(y_val, 1.0)\n\nprint(f\"Training set: {n_train.shape[0]} samples\")\nprint(f\"Validation set: {n_val.shape[0]} samples\")\nprint(f\"P matrix shape: {P_train.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Build Model with L2 Regularization\n\nKey improvements:\n- L2 regularization (1e-4) on all Dense layers\n- LayerNorm for stable training\n- 2 residual blocks\n- Progressive width reduction (1024\u2192512\u2192256\u2192128)\n- Progressive dropout (0.3\u21920.2\u21920.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model_run7(p_shape, k_vocab_size=7, m_vocab_size=6):\n    l2_reg = regularizers.l2(1e-4)\n\n    # Inputs\n    n_input = Input(shape=(1,), name='n')\n    k_input = Input(shape=(1,), name='k', dtype=tf.int32)\n    m_input = Input(shape=(1,), name='m', dtype=tf.int32)\n    P_input = Input(shape=(p_shape,), name='P_flat')\n\n    # Embeddings\n    k_embed = Flatten()(Embedding(k_vocab_size, 32, embeddings_regularizer=l2_reg, name='k_embedding')(k_input))\n    m_embed = Flatten()(Embedding(m_vocab_size, 32, embeddings_regularizer=l2_reg, name='m_embedding')(m_input))\n\n    # Initial P processing\n    x = Dense(256, activation='gelu', kernel_regularizer=l2_reg, name='P_initial_1')(P_input)\n    x = LayerNormalization(name='P_ln1')(x)\n    x = Dropout(0.3)(x)\n\n    x = Dense(512, activation='gelu', kernel_regularizer=l2_reg, name='P_initial_2')(x)\n    x = LayerNormalization(name='P_ln2')(x)\n    x = Dropout(0.2)(x)\n\n    # Combine\n    x = Concatenate(name='combine_embeddings')([n_input, k_embed, m_embed, x])\n\n    # Main dense\n    x = Dense(1024, activation='gelu', kernel_regularizer=l2_reg, name='main_dense1')(x)\n    x = LayerNormalization(name='main_ln1')(x)\n    x = Dropout(0.3)(x)\n\n    # Residual Block 1\n    residual = x\n    x = Dense(1024, activation='gelu', kernel_regularizer=l2_reg, name='res1_dense1')(x)\n    x = LayerNormalization(name='res1_ln1')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(1024, activation='gelu', kernel_regularizer=l2_reg, name='res1_dense2')(x)\n    x = LayerNormalization(name='res1_ln2')(x)\n    x = Add(name='res1_add')([x, residual])\n\n    # Residual Block 2\n    residual = x\n    x = Dense(1024, activation='gelu', kernel_regularizer=l2_reg, name='res2_dense1')(x)\n    x = LayerNormalization(name='res2_ln1')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(1024, activation='gelu', kernel_regularizer=l2_reg, name='res2_dense2')(x)\n    x = LayerNormalization(name='res2_ln2')(x)\n    x = Add(name='res2_add')([x, residual])\n\n    # Progressive reduction\n    x = Dense(512, activation='gelu', kernel_regularizer=l2_reg, name='reduction1')(x)\n    x = LayerNormalization(name='reduction_ln1')(x)\n    x = Dropout(0.2)(x)\n\n    x = Dense(256, activation='gelu', kernel_regularizer=l2_reg, name='reduction2')(x)\n    x = LayerNormalization(name='reduction_ln2')(x)\n    x = Dropout(0.1)(x)\n\n    x = Dense(128, activation='gelu', kernel_regularizer=l2_reg, name='reduction3')(x)\n    x = LayerNormalization(name='reduction_ln3')(x)\n    x = Dropout(0.1)(x)\n\n    # Output\n    log2_pred = Dense(1, activation='linear', kernel_regularizer=l2_reg, name='log2_output')(x)\n    log2_pred_positive = Lambda(lambda z: tf.nn.softplus(z), name='softplus')(log2_pred)\n    m_height_pred = Lambda(lambda z: tf.pow(2.0, z), name='m_height')(log2_pred_positive)\n\n    model = Model(\n        inputs=[n_input, k_input, m_input, P_input],\n        outputs=m_height_pred,\n        name='run7_model'\n    )\n\n    return model\n\np_shape = P_train.shape[1]\nmodel = build_model_run7(\n    p_shape,\n    k_vocab_size=k_train.max()+1,\n    m_vocab_size=m_train.max()+1\n)\n\nprint(f\"Model built successfully!\")\nprint(f\"Total parameters: {model.count_params():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Balanced Loss Function\n\nGroup loss weights to prevent easy case degradation:\n- Easy groups: 3.0x weight (prevent degradation)\n- Medium groups: 1.5x weight\n- Hard groups: 1.0x weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GROUP_LOSS_WEIGHTS = {\n    (4, 2): 3.0, (4, 3): 3.0, (5, 2): 3.0,  # Easy: 3x\n    (4, 4): 1.5, (5, 3): 1.5, (6, 2): 1.5,  # Medium: 1.5x\n    (5, 4): 1.0, (6, 3): 1.0, (4, 5): 1.0,  # Hard: 1x\n}\n\ndef balanced_log2_mse_loss(y_true, y_pred):\n    epsilon = 1e-7\n    y_true = tf.maximum(y_true, epsilon)\n    y_pred = tf.maximum(y_pred, epsilon)\n\n    log2_true = tf.math.log(y_true) / tf.math.log(2.0)\n    log2_pred = tf.math.log(y_pred) / tf.math.log(2.0)\n\n    return tf.reduce_mean(tf.square(log2_true - log2_pred))\n\n# Compute sample weights\nsample_weights_train = np.ones(len(y_train), dtype=np.float32)\n\nfor i, (k, m) in enumerate(zip(k_train, m_train)):\n    key = (k[0], m[0])\n    if key in GROUP_LOSS_WEIGHTS:\n        sample_weights_train[i] = GROUP_LOSS_WEIGHTS[key]\n\nprint(\"Group loss weights applied\")\nprint(f\"Unique weights: {np.unique(sample_weights_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = AdamW(\n    learning_rate=1e-3,\n    weight_decay=1e-4,\n    clipnorm=1.0\n)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=balanced_log2_mse_loss,\n    metrics=[balanced_log2_mse_loss]\n)\n\nprint(\"Model compiled with AdamW\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Callbacks with Easy Case Monitoring\n\n**New Feature:** TierMetricsCallback monitors Easy/Medium/Hard performance separately and stops training if easy cases degrade beyond threshold (0.15)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_log2_mse(y_true, y_pred):\n    epsilon = 1e-7\n    y_true = np.maximum(y_true, epsilon)\n    y_pred = np.maximum(y_pred, epsilon)\n    log2_true = np.log2(y_true)\n    log2_pred = np.log2(y_pred)\n    return np.mean((log2_true - log2_pred) ** 2)\n\n\nclass TierMetricsCallback(Callback):\n    \"\"\"Monitor Easy/Medium/Hard tiers separately\"\"\"\n\n    def __init__(self, val_data, easy_threshold=0.15, patience=5):\n        super().__init__()\n        self.n_val, self.k_val, self.m_val, self.P_val, self.y_val = val_data\n        self.easy_threshold = easy_threshold\n        self.patience = patience\n        self.easy_violations = 0\n        self.best_balanced_metric = float('inf')\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_pred = self.model.predict(\n            [self.n_val, self.k_val, self.m_val, self.P_val],\n            verbose=0\n        ).flatten()\n\n        # Compute per-tier metrics\n        easy_losses = []\n        medium_losses = []\n        hard_losses = []\n\n        for (k, m) in EASY_GROUPS:\n            mask = (self.k_val.flatten() == k) & (self.m_val.flatten() == m)\n            if mask.sum() > 0:\n                loss = compute_log2_mse(self.y_val[mask], y_pred[mask])\n                easy_losses.append(loss)\n\n        for (k, m) in MEDIUM_GROUPS:\n            mask = (self.k_val.flatten() == k) & (self.m_val.flatten() == m)\n            if mask.sum() > 0:\n                loss = compute_log2_mse(self.y_val[mask], y_pred[mask])\n                medium_losses.append(loss)\n\n        for (k, m) in HARD_GROUPS:\n            mask = (self.k_val.flatten() == k) & (self.m_val.flatten() == m)\n            if mask.sum() > 0:\n                loss = compute_log2_mse(self.y_val[mask], y_pred[mask])\n                hard_losses.append(loss)\n\n        easy_avg = np.mean(easy_losses) if easy_losses else 0\n        medium_avg = np.mean(medium_losses) if medium_losses else 0\n        hard_avg = np.mean(hard_losses) if hard_losses else 0\n\n        balanced_metric = (easy_avg + medium_avg + hard_avg) / 3\n\n        if balanced_metric < self.best_balanced_metric:\n            self.best_balanced_metric = balanced_metric\n\n        print(f\"\\n  Tier Metrics - Easy: {easy_avg:.4f} | Medium: {medium_avg:.4f} | Hard: {hard_avg:.4f} | Balanced: {balanced_metric:.4f}\")\n\n        if easy_avg > self.easy_threshold:\n            self.easy_violations += 1\n            print(f\"  \u26a0\ufe0f  WARNING: Easy cases at {easy_avg:.4f} (threshold: {self.easy_threshold}) - violation {self.easy_violations}/{self.patience}\")\n\n            if self.easy_violations >= self.patience:\n                print(f\"\\n  \ud83d\uded1 STOPPING: Easy cases degraded for {self.patience} consecutive epochs\")\n                self.model.stop_training = True\n        else:\n            self.easy_violations = 0\n            print(f\"  \u2705 Easy cases OK ({easy_avg:.4f} < {self.easy_threshold})\")\n\n\ndef lr_schedule(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * 0.95\n\nlr_scheduler = LearningRateScheduler(lr_schedule, verbose=0)\n\ntier_callback = TierMetricsCallback(\n    val_data=(n_val, k_val, m_val, P_val, y_val),\n    easy_threshold=0.15,\n    patience=5\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=15, min_lr=1e-6, verbose=1),\n    ModelCheckpoint('best_model_run7.h5', monitor='val_loss', save_best_only=True, verbose=1),\n    lr_scheduler,\n    tier_callback\n]\n\nprint(\"Callbacks configured with easy case monitoring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"TRAINING MODEL - RUN 7\")\nprint(\"=\"*70)\nprint(f\"Batch size: 256\")\nprint(f\"Max epochs: 250\")\nprint(f\"Training samples: {len(y_train):,}\")\nprint(f\"Validation samples: {len(y_val):,}\")\nprint()\n\nhistory = model.fit(\n    [n_train, k_train, m_train, P_train],\n    y_train,\n    sample_weight=sample_weights_train,\n    validation_data=([n_val, k_val, m_val, P_val], y_val),\n    epochs=250,\n    batch_size=256,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"\\nTraining completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights('best_model_run7.h5')\n\ny_pred_train = model.predict([n_train, k_train, m_train, P_train], verbose=0).flatten()\ny_pred_val = model.predict([n_val, k_val, m_val, P_val], verbose=0).flatten()\n\ntrain_log2_mse = compute_log2_mse(y_train, y_pred_train)\nval_log2_mse = compute_log2_mse(y_val, y_pred_val)\n\nprint(f\"Training log2-MSE: {train_log2_mse:.6f}\")\nprint(f\"Validation log2-MSE: {val_log2_mse:.6f}\")\nprint(f\"Train-Val gap: {abs(train_log2_mse - val_log2_mse):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Per-Group Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group_metrics = defaultdict(lambda: {'true': [], 'pred': []})\n\nfor i in range(len(y_val)):\n    k = k_val[i, 0]\n    m = m_val[i, 0]\n    group_metrics[(k, m)]['true'].append(y_val[i])\n    group_metrics[(k, m)]['pred'].append(y_pred_val[i])\n\nimport os\nos.makedirs('run_7', exist_ok=True)\n\nrun2_reference = {\n    (4, 2): 0.103043, (4, 3): 0.107653, (4, 4): 0.209655, (4, 5): 1.422106,\n    (5, 2): 0.096024, (5, 3): 0.227183, (5, 4): 0.957722,\n    (6, 2): 0.355892, (6, 3): 1.083320\n}\n\nrun6_reference = {\n    (4, 2): 0.405360, (4, 3): 0.460462, (4, 4): 0.127370, (4, 5): 0.224046,\n    (5, 2): 0.450569, (5, 3): 0.137842, (5, 4): 0.200213,\n    (6, 2): 0.155255, (6, 3): 0.168260\n}\n\nprint(\"\\nPer-Group Performance:\")\nprint(\"Run 2     | Run 6*    | Run 7     | vs R2      | n\")\nprint(\"-\"*70)\n\neasy_sum, medium_sum, hard_sum = 0, 0, 0\neasy_count, medium_count, hard_count = 0, 0, 0\n\nfor (k, m), data in sorted(group_metrics.items()):\n    true_vals = np.array(data['true'])\n    pred_vals = np.array(data['pred'])\n    group_log2_mse = compute_log2_mse(true_vals, pred_vals)\n\n    run2_val = run2_reference.get((k, m), None)\n    run6_val = run6_reference.get((k, m), None)\n\n    if run2_val:\n        change_r2 = ((run2_val - group_log2_mse) / run2_val) * 100\n        change_r2_str = f\"{change_r2:+.1f}%\"\n    else:\n        change_r2_str = \"N/A\"\n\n    run2_str = f\"{run2_val:.6f}\" if run2_val else \"N/A\"\n    run6_str = f\"{run6_val:.6f}\" if run6_val else \"N/A\"\n\n    print(f\"k={k},m={m}  {run2_str:<10} {run6_str:<10} {group_log2_mse:.6f}  {change_r2_str:<10} n={len(true_vals)}\")\n\n    if (k, m) in EASY_GROUPS:\n        easy_sum += group_log2_mse\n        easy_count += 1\n    elif (k, m) in MEDIUM_GROUPS:\n        medium_sum += group_log2_mse\n        medium_count += 1\n    elif (k, m) in HARD_GROUPS:\n        hard_sum += group_log2_mse\n        hard_count += 1\n\nprint(\"\\n* Run 6 had data leakage - metrics are invalid\")\n\neasy_avg = easy_sum / easy_count if easy_count > 0 else 0\nmedium_avg = medium_sum / medium_count if medium_count > 0 else 0\nhard_avg = hard_sum / hard_count if hard_count > 0 else 0\nbalanced_metric = (easy_avg + medium_avg + hard_avg) / 3\n\nprint(f\"\\nEasy cases: {easy_avg:.6f} (Target: < 0.15)\")\nprint(f\"Medium cases: {medium_avg:.6f} (Target: 0.20-0.30)\")\nprint(f\"Hard cases: {hard_avg:.6f} (Target: 0.70-1.20)\")\nprint(f\"Balanced metric: {balanced_metric:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Generate Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Train Loss', linewidth=2)\nplt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\nplt.xlabel('Epoch', fontsize=12)\nplt.ylabel('Log2-MSE Loss', fontsize=12)\nplt.title('Training History - Run 7', fontsize=14, fontweight='bold')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nstart_epoch = int(len(history.history['loss']) * 0.2)\nplt.plot(range(start_epoch, len(history.history['loss'])),\n         history.history['loss'][start_epoch:],\n         label='Train Loss', linewidth=2)\nplt.plot(range(start_epoch, len(history.history['val_loss'])),\n         history.history['val_loss'][start_epoch:],\n         label='Val Loss', linewidth=2)\nplt.xlabel('Epoch', fontsize=12)\nplt.ylabel('Log2-MSE Loss', fontsize=12)\nplt.title('Training History (Last 80%)', fontsize=14, fontweight='bold')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('run_7/training_history_run7.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.scatter(y_val, y_pred_val, alpha=0.3, s=10)\nplt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()],\n         'r--', linewidth=2, label='Perfect Prediction')\nplt.xlabel('True m-Height', fontsize=12)\nplt.ylabel('Predicted m-Height', fontsize=12)\nplt.title('Predictions vs True Values - Run 7', fontsize=14, fontweight='bold')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nplt.scatter(y_val, y_pred_val, alpha=0.3, s=10)\nplt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()],\n         'r--', linewidth=2, label='Perfect Prediction')\nplt.xlabel('True m-Height (log scale)', fontsize=12)\nplt.ylabel('Predicted m-Height (log scale)', fontsize=12)\nplt.title('Predictions vs True Values - Log Scale', fontsize=14, fontweight='bold')\nplt.xscale('log')\nplt.yscale('log')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('run_7/predictions_scatter_run7.png', dpi=150, bbox_inches='tight')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"FINAL RESULTS SUMMARY - RUN 7\")\nprint(\"=\"*70)\nprint(f\"Training samples: {len(y_train):,}\")\nprint(f\"Validation samples: {len(y_val):,}\")\nprint(f\"Model parameters: {model.count_params():,}\")\nprint()\nprint(f\"Training log2-MSE:   {train_log2_mse:.6f}\")\nprint(f\"Validation log2-MSE: {val_log2_mse:.6f}\")\nprint(f\"Train-Val gap:       {abs(train_log2_mse - val_log2_mse):.6f}\")\nprint(f\"Target to beat:      0.374000\")\nprint()\n\nif val_log2_mse < 0.374:\n    improvement = ((0.374 - val_log2_mse) / 0.374) * 100\n    print(f\"\u2705 SUCCESS! Beat target by {improvement:.1f}%\")\nelse:\n    deficit = ((val_log2_mse - 0.374) / 0.374) * 100\n    print(f\"\u26a0\ufe0f  Did not beat target (worse by {deficit:.1f}%)\")\n\nprint()\nprint(f\"Easy cases:   {easy_avg:.6f} (Target: < 0.15)\")\nprint(f\"Medium cases: {medium_avg:.6f} (Target: 0.20-0.30)\")\nprint(f\"Hard cases:   {hard_avg:.6f} (Target: 0.70-1.20)\")\nprint(f\"Balanced:     {balanced_metric:.6f}\")\nprint()\nprint(\"Run 7 Improvements:\")\nprint(\"  \u2705 Augmentation AFTER split (no data leakage)\")\nprint(\"  \u2705 Reduced augmentation (3/2/1 vs 50/25/0)\")\nprint(\"  \u2705 Increased noise scale (5% vs 2%)\")\nprint(\"  \u2705 Easy case monitoring\")\nprint(\"  \u2705 Balanced loss weighting\")\nprint(\"  \u2705 L2 regularization\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}