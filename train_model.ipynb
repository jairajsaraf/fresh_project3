{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height Prediction Model Training Script - Run 1 (Best Performing)\n",
    "\n",
    "**Objective:** Beat validation log2-MSE of 0.374 using TensorFlow\n",
    "\n",
    "**Performance:** Validation log2-MSE = **0.495** (Best among train_model.py, train_model_v3.py, train_model_v4.py)\n",
    "\n",
    "## Key Improvements\n",
    "\n",
    "1. Dataset rebalancing (~9,000 samples per (k,m) combination)\n",
    "2. Predicting log2(m-height) instead of raw values\n",
    "3. Advanced architecture with attention and residual blocks\n",
    "4. Group-weighted loss (1.0-5.0x for hard cases)\n",
    "5. Stronger regularization and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Embedding, Flatten, Concatenate,\n",
    "    Dropout, BatchNormalization, Add, Reshape, MultiHeadAttention, Lambda\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEIGHT PREDICTION MODEL - TRAINING SCRIPT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "Using augmented dataset (properly merged DS-1 + DS-2 + DS-3 with balanced augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 1: Loading Data\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "with open('augmented_n_k_m_P.pkl', 'rb') as f:\n",
    "    inputs_raw = pickle.load(f)\n",
    "\n",
    "with open('augmented_mHeights.pkl', 'rb') as f:\n",
    "    outputs_raw = pickle.load(f)\n",
    "\n",
    "print(f\"Raw input samples: {len(inputs_raw)}\")\n",
    "print(f\"Raw output samples: {len(outputs_raw)}\")\n",
    "if len(inputs_raw) > 0:\n",
    "    sample = inputs_raw[0]\n",
    "    print(f\"Sample structure: [n={sample[0]}, k={sample[1]}, m={sample[2]}, P_matrix shape={sample[3].shape}]\")\n",
    "print(f\"Output range: [{np.min(outputs_raw):.2f}, {np.max(outputs_raw):.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analyze Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 2: Analyzing Class Distribution (BEFORE Rebalancing)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Group samples by (k, m) combinations\n",
    "groups = defaultdict(list)\n",
    "for i, sample in enumerate(inputs_raw):\n",
    "    k = int(sample[1])\n",
    "    m = int(sample[2])\n",
    "    groups[(k, m)].append(i)\n",
    "\n",
    "print(f\"Total unique (k,m) combinations: {len(groups)}\")\n",
    "print(\"\\nDistribution by (k,m):\")\n",
    "total_samples = len(inputs_raw)\n",
    "for (k, m), indices in sorted(groups.items()):\n",
    "    count = len(indices)\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"  k={k}, m={m}: {count:6d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "max_count = max(len(indices) for indices in groups.values())\n",
    "min_count = min(len(indices) for indices in groups.values())\n",
    "print(f\"\\nImbalance ratio: {max_count/min_count:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 3: Verifying Dataset Balance\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"Using pre-balanced augmented dataset (12,000 samples per (k,m) group)\")\n",
    "print(f\"Dataset already balanced at: {len(inputs_raw):,} total samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 4: Preparing Data for Training\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "inputs_rebalanced = inputs_raw\n",
    "outputs_rebalanced = outputs_raw\n",
    "\n",
    "# Extract n, k, m values and flatten P matrices\n",
    "n_values = []\n",
    "k_values = []\n",
    "m_values = []\n",
    "P_matrices_flattened = []\n",
    "\n",
    "for sample in inputs_rebalanced:\n",
    "    n_values.append(sample[0])\n",
    "    k_values.append(sample[1])\n",
    "    m_values.append(sample[2])\n",
    "    P_matrices_flattened.append(sample[3].flatten())\n",
    "\n",
    "n_values = np.array(n_values, dtype=np.float32).reshape(-1, 1)\n",
    "k_values = np.array(k_values, dtype=np.int32).reshape(-1, 1)\n",
    "m_values = np.array(m_values, dtype=np.int32).reshape(-1, 1)\n",
    "outputs_array = np.array(outputs_rebalanced, dtype=np.float32)\n",
    "\n",
    "# Pad P matrices to same size\n",
    "max_p_size = max(len(p) for p in P_matrices_flattened)\n",
    "P_matrices_padded = []\n",
    "\n",
    "for p in P_matrices_flattened:\n",
    "    if len(p) < max_p_size:\n",
    "        padded = np.zeros(max_p_size, dtype=np.float32)\n",
    "        padded[:len(p)] = p\n",
    "        P_matrices_padded.append(padded)\n",
    "    else:\n",
    "        P_matrices_padded.append(p)\n",
    "\n",
    "P_matrices = np.array(P_matrices_padded, dtype=np.float32)\n",
    "\n",
    "# Normalize P matrices\n",
    "scaler = StandardScaler()\n",
    "P_matrices_normalized = scaler.fit_transform(P_matrices)\n",
    "\n",
    "outputs_array = np.maximum(outputs_array, 1.0)\n",
    "\n",
    "print(f\"n_values shape: {n_values.shape}\")\n",
    "print(f\"k_values shape: {k_values.shape}, range: [{k_values.min()}, {k_values.max()}]\")\n",
    "print(f\"m_values shape: {m_values.shape}, range: [{m_values.min()}, {m_values.max()}]\")\n",
    "print(f\"P_matrices shape: {P_matrices.shape}\")\n",
    "print(f\"P matrices normalized: mean={P_matrices_normalized.mean():.4f}, std={P_matrices_normalized.std():.4f}\")\n",
    "print(f\"Output (m-height) range: [{outputs_array.min():.2f}, {outputs_array.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Stratified Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 5: Creating Stratified Train-Validation Split\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Create stratification labels based on (k, m) combinations\n",
    "stratify_labels = k_values.flatten() * 10 + m_values.flatten()\n",
    "\n",
    "# Split data (85% train, 15% validation)\n",
    "(n_train, n_val,\n",
    " k_train, k_val,\n",
    " m_train, m_val,\n",
    " P_train, P_val,\n",
    " y_train, y_val,\n",
    " strat_train, strat_val) = train_test_split(\n",
    "    n_values, k_values, m_values, P_matrices_normalized, outputs_array,\n",
    "    stratify_labels,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=stratify_labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(y_train)}\")\n",
    "print(f\"Validation samples: {len(y_val)}\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nValidation set distribution:\")\n",
    "val_groups = defaultdict(int)\n",
    "for k, m in zip(k_val.flatten(), m_val.flatten()):\n",
    "    val_groups[(k, m)] += 1\n",
    "for (k, m), count in sorted(val_groups.items()):\n",
    "    percentage = (count / len(y_val)) * 100\n",
    "    print(f\"  k={k}, m={m}: {count:5d} samples ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5B: Compute Sample Weights for Group-Weighted Loss\n",
    "\n",
    "Higher k and m values get higher weights to force the model to focus on difficult groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 5B: Computing Sample Weights for Group-Weighted Loss\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Define per-group weights based on complexity\n",
    "group_weights = {\n",
    "    (4, 2): 1.0,   # baseline\n",
    "    (4, 3): 1.0,\n",
    "    (5, 2): 1.0,\n",
    "    (4, 4): 1.5,   # increase focus\n",
    "    (5, 3): 1.5,\n",
    "    (6, 2): 2.0,   # significant focus\n",
    "    (5, 4): 3.0,   # high focus\n",
    "    (6, 3): 3.0,\n",
    "    (4, 5): 5.0,   # maximum focus on worst performer\n",
    "}\n",
    "\n",
    "# Compute sample weights for training set\n",
    "sample_weights_train = np.array([\n",
    "    group_weights.get((int(k), int(m)), 1.0)\n",
    "    for k, m in zip(k_train.flatten(), m_train.flatten())\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Sample weights distribution:\")\n",
    "for (k, m), weight in sorted(group_weights.items()):\n",
    "    count = np.sum((k_train.flatten() == k) & (m_train.flatten() == m))\n",
    "    print(f\"  k={k}, m={m}: weight={weight:.1f} ({count:5d} samples)\")\n",
    "\n",
    "print(f\"\\nSample weights shape: {sample_weights_train.shape}\")\n",
    "print(f\"Sample weights range: [{sample_weights_train.min():.1f}, {sample_weights_train.max():.1f}]\")\n",
    "print(f\"Average weight: {sample_weights_train.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build Model\n",
    "\n",
    "Advanced model with:\n",
    "- Embeddings for categorical k and m\n",
    "- Deep processing of P matrix with attention\n",
    "- Residual blocks\n",
    "- Output: log2(m-height) with constraint ≥ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(p_shape, k_vocab_size=7, m_vocab_size=6):\n",
    "    # Inputs\n",
    "    n_input = Input(shape=(1,), name='n_input')\n",
    "    k_input = Input(shape=(1,), name='k_input', dtype=tf.int32)\n",
    "    m_input = Input(shape=(1,), name='m_input', dtype=tf.int32)\n",
    "    P_input = Input(shape=(p_shape,), name='P_input')\n",
    "\n",
    "    # Embeddings for categorical variables\n",
    "    k_embed = Flatten()(Embedding(k_vocab_size, 32, name='k_embedding')(k_input))\n",
    "    m_embed = Flatten()(Embedding(m_vocab_size, 32, name='m_embedding')(m_input))\n",
    "\n",
    "    # P matrix processing\n",
    "    x = Dense(256, activation='gelu')(P_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='gelu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Multi-head attention on P features\n",
    "    x_attn = Reshape((1, 512))(x)\n",
    "    x_attn = MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.1)(x_attn, x_attn)\n",
    "    x_attn = Flatten()(x_attn)\n",
    "\n",
    "    # Combine all features\n",
    "    combined = Concatenate()([n_input, k_embed, m_embed, x_attn])\n",
    "\n",
    "    # Deep network with residual connections\n",
    "    x = Dense(1024, activation='gelu')(combined)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # 4 residual blocks\n",
    "    for i in range(4):\n",
    "        residual = x\n",
    "        x = Dense(1024, activation='gelu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(1024, activation='gelu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([x, residual])\n",
    "\n",
    "    # Final dense layers\n",
    "    x = Dense(512, activation='gelu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='gelu')(x)\n",
    "\n",
    "    # Output layer: Predict log2(m-height), then convert to m-height\n",
    "    log2_pred = Dense(1, activation='linear', name='log2_prediction')(x)\n",
    "    \n",
    "    # Ensure log2_pred ≥ 0 (so m-height ≥ 1) using softplus\n",
    "    log2_positive = Lambda(lambda x: tf.nn.softplus(x), name='softplus_activation')(log2_pred)\n",
    "    \n",
    "    # Convert to m-height: 2^(log2_pred)\n",
    "    output = Lambda(lambda x: tf.pow(2.0, x), name='m_height_output')(log2_positive)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[n_input, k_input, m_input, P_input],\n",
    "        outputs=output,\n",
    "        name='height_prediction_model'\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "p_shape = P_train.shape[1]\n",
    "model = build_model(p_shape, k_vocab_size=k_values.max()+1, m_vocab_size=m_values.max()+1)\n",
    "\n",
    "print(f\"Model built successfully!\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Define Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2_mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function: MSE in log2 space\n",
    "    Loss = mean((log2(y_true) - log2(y_pred))^2)\n",
    "    \"\"\"\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Ensure positive values\n",
    "    y_true = tf.maximum(y_true, epsilon)\n",
    "    y_pred = tf.maximum(y_pred, epsilon)\n",
    "\n",
    "    # Convert to log2\n",
    "    log2_true = tf.math.log(y_true) / tf.math.log(2.0)\n",
    "    log2_pred = tf.math.log(y_pred) / tf.math.log(2.0)\n",
    "\n",
    "    # MSE in log2 space\n",
    "    return tf.reduce_mean(tf.square(log2_true - log2_pred))\n",
    "\n",
    "print(\"Custom log2-MSE loss function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 8: Compiling Model\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Reduced learning rate (1e-3 -> 5e-4) and increased weight decay (1e-4 -> 1e-3)\n",
    "optimizer = AdamW(learning_rate=5e-4, weight_decay=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=log2_mse_loss,\n",
    "    metrics=[log2_mse_loss]\n",
    ")\n",
    "\n",
    "print(\"Model compiled with AdamW optimizer and log2-MSE loss\")\n",
    "print(f\"  Learning rate: 5e-4 (reduced from 1e-3)\")\n",
    "print(f\"  Weight decay: 1e-3 (increased from 1e-4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=30,  # Reduced from 50\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"  - EarlyStopping (patience=30)\")\n",
    "print(\"  - ReduceLROnPlateau (patience=20, factor=0.5)\")\n",
    "print(\"  - ModelCheckpoint (saves best model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 10: TRAINING MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Batch size: 256\")\n",
    "print(f\"Max epochs: 200\")\n",
    "print(f\"Early stopping patience: 30\")\n",
    "print(f\"Group-weighted loss: ENABLED (weights 1.0-5.0x)\")\n",
    "\n",
    "history = model.fit(\n",
    "    [n_train, k_train, m_train, P_train],\n",
    "    y_train,\n",
    "    sample_weight=sample_weights_train,\n",
    "    validation_data=([n_val, k_val, m_val, P_val], y_val),\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 11: EVALUATING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict([n_train, k_train, m_train, P_train], verbose=0).flatten()\n",
    "y_pred_val = model.predict([n_val, k_val, m_val, P_val], verbose=0).flatten()\n",
    "\n",
    "# Compute overall log2-MSE\n",
    "def compute_log2_mse(y_true, y_pred):\n",
    "    epsilon = 1e-7\n",
    "    y_true = np.maximum(y_true, epsilon)\n",
    "    y_pred = np.maximum(y_pred, epsilon)\n",
    "    log2_true = np.log2(y_true)\n",
    "    log2_pred = np.log2(y_pred)\n",
    "    return np.mean((log2_true - log2_pred) ** 2)\n",
    "\n",
    "train_log2_mse = compute_log2_mse(y_train, y_pred_train)\n",
    "val_log2_mse = compute_log2_mse(y_val, y_pred_val)\n",
    "\n",
    "print(f\"Training log2-MSE: {train_log2_mse:.6f}\")\n",
    "print(f\"Validation log2-MSE: {val_log2_mse:.6f}\")\n",
    "\n",
    "# Check prediction constraints\n",
    "print(\"\\nPrediction Statistics:\")\n",
    "print(f\"  Train predictions - Min: {y_pred_train.min():.4f}, Max: {y_pred_train.max():.4f}\")\n",
    "print(f\"  Val predictions - Min: {y_pred_val.min():.4f}, Max: {y_pred_val.max():.4f}\")\n",
    "print(f\"  All predictions ≥ 1.0: {(y_pred_val.min() >= 1.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Per-Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PER-GROUP PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute per-(k,m) metrics for validation set\n",
    "group_metrics = defaultdict(lambda: {'true': [], 'pred': []})\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    k = k_val[i, 0]\n",
    "    m = m_val[i, 0]\n",
    "    group_metrics[(k, m)]['true'].append(y_val[i])\n",
    "    group_metrics[(k, m)]['pred'].append(y_pred_val[i])\n",
    "\n",
    "# Save to file and print\n",
    "with open('per_group_performance.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"PER-GROUP PERFORMANCE BREAKDOWN\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "\n",
    "    print(\"\\nValidation Log2-MSE by (k,m) combination:\")\n",
    "    f.write(\"Validation Log2-MSE by (k,m) combination:\\n\")\n",
    "    f.write(\"-\"*70 + \"\\n\")\n",
    "\n",
    "    for (k, m), data in sorted(group_metrics.items()):\n",
    "        true_vals = np.array(data['true'])\n",
    "        pred_vals = np.array(data['pred'])\n",
    "        group_log2_mse = compute_log2_mse(true_vals, pred_vals)\n",
    "\n",
    "        output_line = f\"  k={k}, m={m}: {group_log2_mse:.6f} (n={len(true_vals)} samples)\"\n",
    "        print(output_line)\n",
    "        f.write(output_line + \"\\n\")\n",
    "\n",
    "print(\"\\nPer-group performance saved to: per_group_performance.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training History\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Log2-MSE Loss', fontsize=12)\n",
    "plt.title('Training History', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot last 80% of training\n",
    "start_epoch = int(len(history.history['loss']) * 0.2)\n",
    "plt.plot(range(start_epoch, len(history.history['loss'])),\n",
    "         history.history['loss'][start_epoch:],\n",
    "         label='Train Loss', linewidth=2)\n",
    "plt.plot(range(start_epoch, len(history.history['val_loss'])),\n",
    "         history.history['val_loss'][start_epoch:],\n",
    "         label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Log2-MSE Loss', fontsize=12)\n",
    "plt.title('Training History (Last 80%)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Predictions vs True Values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_pred_val, alpha=0.3, s=10)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()],\n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('True m-Height', fontsize=12)\n",
    "plt.ylabel('Predicted m-Height', fontsize=12)\n",
    "plt.title('Predictions vs True Values (Validation Set)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_val, y_pred_val, alpha=0.3, s=10)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()],\n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('True m-Height (log scale)', fontsize=12)\n",
    "plt.ylabel('Predicted m-Height (log scale)', fontsize=12)\n",
    "plt.title('Predictions vs True Values - Log Scale', fontsize=14, fontweight='bold')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training samples: {len(y_train):,}\")\n",
    "print(f\"Validation samples: {len(y_val):,}\")\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n",
    "print()\n",
    "print(f\"Training log2-MSE:   {train_log2_mse:.6f}\")\n",
    "print(f\"Validation log2-MSE: {val_log2_mse:.6f}\")\n",
    "print(f\"Target to beat:      0.374000\")\n",
    "print()\n",
    "\n",
    "if val_log2_mse < 0.374:\n",
    "    improvement = ((0.374 - val_log2_mse) / 0.374) * 100\n",
    "    print(f\"✅ SUCCESS! Beat target by {improvement:.1f}%\")\n",
    "    print(f\"   Improvement: {0.374 - val_log2_mse:.6f}\")\n",
    "else:\n",
    "    deficit = ((val_log2_mse - 0.374) / 0.374) * 100\n",
    "    print(f\"❌ Did not beat target (worse by {deficit:.1f}%)\")\n",
    "    print(f\"   Need to improve by: {val_log2_mse - 0.374:.6f}\")\n",
    "\n",
    "print()\n",
    "print(\"All predictions ≥ 1.0:\", \"✅ Yes\" if y_pred_val.min() >= 1.0 else \"❌ No\")\n",
    "print(f\"Prediction range: [{y_pred_val.min():.2f}, {y_pred_val.max():.2f}]\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"DELIVERABLES SAVED:\")\n",
    "print(\"=\"*70)\n",
    "print(\"  1. best_model.h5 - Trained model weights\")\n",
    "print(\"  2. training_history.png - Loss curves\")\n",
    "print(\"  3. predictions_scatter.png - Prediction quality plots\")\n",
    "print(\"  4. per_group_performance.txt - Detailed per-(k,m) metrics\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
